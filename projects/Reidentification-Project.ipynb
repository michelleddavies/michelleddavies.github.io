{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reidentication Project\n",
    "I made a python notebook that takes any public dataset and then analyzes and calculates it's k-anonymity, l-diversity and t-closeness using my own implementation of Pandas and Numpy functions. This will allow for analysis of the anonymity of the given data.\n",
    "\n",
    "Written & Tested by Chelle Davies, July 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "## Function to calculate k-anonymity\n",
    "def calculate_k_anonymity(df, quasi_identifiers):\n",
    "    return df.groupby(quasi_identifiers).size()\n",
    "\n",
    "## Function to calculate l-diversity\n",
    "def calculate_l_diversity(df, quasi_identifiers, sensitive_attribute):\n",
    "    def diversity(group):\n",
    "        return group[sensitive_attribute].nunique()\n",
    "    return df.groupby(quasi_identifiers).apply(diversity)\n",
    "\n",
    "## Function to calculate t-closeness\n",
    "def calculate_t_closeness(df, quasi_identifiers, sensitive_attribute):\n",
    "    global_dist = df[sensitive_attribute].value_counts(normalize=True)\n",
    "    def closeness(group):\n",
    "        local_dist = group[sensitive_attribute].value_counts(normalize=True)\n",
    "        return np.sum(np.abs(local_dist - global_dist))\n",
    "    return df.groupby(quasi_identifiers).apply(closeness)\n",
    "\n",
    "def flag_re_identifiability(df, quasi_identifiers, sensitive_attribute):\n",
    "    k_anonymity = calculate_k_anonymity(df, quasi_identifiers)\n",
    "    l_diversity = calculate_l_diversity(df, quasi_identifiers, sensitive_attribute)\n",
    "    t_closeness = calculate_t_closeness(df, quasi_identifiers, sensitive_attribute)\n",
    "    df['k_anonymity'] = df[quasi_identifiers].apply(tuple, axis=1).map(k_anonymity)\n",
    "    df['l_diversity'] = df[quasi_identifiers].apply(tuple, axis=1).map(l_diversity)\n",
    "    df['t_closeness'] = df[quasi_identifiers].apply(tuple, axis=1).map(t_closeness)\n",
    "    return df\n",
    "\n",
    "## Infinite loop to get inputs until a blank entry\n",
    "def get_user_inputs():\n",
    "    quasi_identifiers = []\n",
    "    inputs = []\n",
    "    while True:\n",
    "        user_input = input(\"Enter a column name or index that is a quasi_identifier (leave blank to finish): \")\n",
    "        if user_input == \"\":\n",
    "            break\n",
    "        inputs.append(user_input)\n",
    "    for item in inputs:\n",
    "        try:\n",
    "            quasi_identifiers.append(int(item))\n",
    "        except ValueError:\n",
    "            pass  # Ignore the item if it cannot be converted\n",
    "    return quasi_identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the file path of the public data from user input\n",
    "file_path = input(\"Enter the file path for the data, as a CSV or Parquet file: \")\n",
    "if 'parquet' in file_path.lower():\n",
    "    df = pd.read_parquet(file_path, header=None)\n",
    "else:\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the quasi-identifiers and sensitive attribute of data\n",
    "quasi_identifiers = get_user_inputs()\n",
    "print(\"quasi_identifiers=\", quasi_identifiers)\n",
    "try:\n",
    "    sensitive_attribute = int(input(\"Enter the column name or index that is the sensitive attribute: \"))\n",
    "except:\n",
    "    sensitive_attribute = None \n",
    "print(\"sensitive_attribute =\", sensitive_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = flag_re_identifiability(df, quasi_identifiers, sensitive_attribute)\n",
    "\n",
    "# Flagging rows with >= 80% likelihood of re-identification\n",
    "df['re_identifiability_likelihood'] = np.where(\n",
    "    (df['k_anonymity'] <= (0.2 * len(df))) & \n",
    "    (df['l_diversity'] <= 1) & \n",
    "    (df['t_closeness'] >= (0.8 * df['t_closeness'].max())), \n",
    "    'High', 'Low'\n",
    ")\n",
    "high_risk_df = df[df['re_identifiability_likelihood'] == 'High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics summary\n",
    "stats_summary = {\n",
    "    'k_anonymity': df['k_anonymity'].describe(),\n",
    "    'l_diversity': df['l_diversity'].describe(),\n",
    "    't_closeness': df['t_closeness'].describe(),\n",
    "    'high_risk_rows_count': high_risk_df.shape[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the high risk dataframe and the overall statistics summary\n",
    "high_risk_df_copy = high_risk_df.copy()\n",
    "summary_df = pd.DataFrame(stats_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the indexes of the rows in high_risk_df_copy\n",
    "high_risk_indexes = high_risk_df_copy.index.tolist()\n",
    "print(\"\\nNumber of Indexes for High Risk Rows:\")\n",
    "print(len(high_risk_indexes), \" out of \", len(df), \" rows ({}%)\".format(round((len(high_risk_indexes)/len(df))*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataframes - Interpretation\n",
    "print(\"\\nInterpretation of Summary Statistics:\")\n",
    "\n",
    "# Conditional interpretation for k-anonymity\n",
    "k_anonymity_mean = summary_df['k_anonymity']['mean']\n",
    "k_anonymity_median = summary_df['k_anonymity']['50%']\n",
    "if k_anonymity_mean > 20:\n",
    "    print(f\"\\nK-Anonymity: Mean: {k_anonymity_mean} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"\\nK-Anonymity: Mean: {k_anonymity_mean} (Moderate to High Risk)\")\n",
    "if k_anonymity_median > 20:\n",
    "    print(f\"Median: {k_anonymity_median} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"Median: {k_anonymity_median} (Moderate to High Risk)\")\n",
    "\n",
    "# Conditional interpretation for l-diversity\n",
    "l_diversity_mean = summary_df['l_diversity']['mean']\n",
    "l_diversity_median = summary_df['l_diversity']['50%']\n",
    "if l_diversity_mean > 5:\n",
    "    print(f\"\\nL-Diversity: Mean: {l_diversity_mean} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"\\nL-Diversity: Mean: {l_diversity_mean} (Moderate to High Risk)\")\n",
    "if l_diversity_median > 5:\n",
    "    print(f\"Median: {l_diversity_median} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"Median: {l_diversity_median} (Moderate to High Risk)\")\n",
    "\n",
    "# Conditional interpretation for t-closeness\n",
    "t_closeness_mean = summary_df['t_closeness']['mean']\n",
    "t_closeness_median = summary_df['t_closeness']['50%']\n",
    "if t_closeness_mean <= 0.05:\n",
    "    print(f\"\\nT-Closeness: Mean: {t_closeness_mean} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"\\nT-Closeness: Mean: {t_closeness_mean} (Moderate to High Risk)\")\n",
    "if t_closeness_median <= 0.05:\n",
    "    print(f\"Median: {t_closeness_median} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"Median: {t_closeness_median} (Moderate to High Risk)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStatistics Summary:\")\n",
    "for column in summary_df.columns:\n",
    "    if column != 'high_risk_rows_count':\n",
    "        print(f\"\\nSummary statistics for {column}:\")\n",
    "        print(f\"Mean: {summary_df[column]['mean']}\")\n",
    "        print(f\"Median: {summary_df[column]['50%']}\")\n",
    "        print(f\"Standard Deviation: {summary_df[column]['std']}\")\n",
    "print(f\"\\nTotal Hish Risk Count: {summary_df['high_risk_rows_count']['count']} out of {len(df)}, ({round((summary_df['high_risk_rows_count']['count']/len(df))*100, 2)}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
