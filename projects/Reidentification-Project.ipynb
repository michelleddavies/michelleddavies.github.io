{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reidentication Project\n",
    "I made a python notebook that takes any public dataset and then analyzes and calculates it's k-anonymity, l-diversity and t-closeness using my own implementation of Pandas and Numpy functions. This will allow for analysis of the anonymity of the given data.\n",
    "\n",
    "Written & Tested by Chelle Davies, July 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "## Function to calculate k-anonymity\n",
    "def calculate_k_anonymity(df, quasi_identifiers):\n",
    "    return df.groupby(quasi_identifiers).size()\n",
    "\n",
    "## Function to calculate l-diversity\n",
    "def calculate_l_diversity(df, quasi_identifiers, sensitive_attribute):\n",
    "    def diversity(group):\n",
    "        return group[sensitive_attribute].nunique()\n",
    "    return df.groupby(quasi_identifiers).apply(diversity)\n",
    "\n",
    "## Function to calculate t-closeness\n",
    "def calculate_t_closeness(df, quasi_identifiers, sensitive_attribute):\n",
    "    global_dist = df[sensitive_attribute].value_counts(normalize=True)\n",
    "    def closeness(group):\n",
    "        local_dist = group[sensitive_attribute].value_counts(normalize=True)\n",
    "        return np.sum(np.abs(local_dist - global_dist))\n",
    "    return df.groupby(quasi_identifiers).apply(closeness)\n",
    "\n",
    "def flag_re_identifiability(df, quasi_identifiers, sensitive_attribute):\n",
    "    k_anonymity = calculate_k_anonymity(df, quasi_identifiers)\n",
    "    l_diversity = calculate_l_diversity(df, quasi_identifiers, sensitive_attribute)\n",
    "    t_closeness = calculate_t_closeness(df, quasi_identifiers, sensitive_attribute)\n",
    "    df['k_anonymity'] = df[quasi_identifiers].apply(tuple, axis=1).map(k_anonymity)\n",
    "    df['l_diversity'] = df[quasi_identifiers].apply(tuple, axis=1).map(l_diversity)\n",
    "    df['t_closeness'] = df[quasi_identifiers].apply(tuple, axis=1).map(t_closeness)\n",
    "    return df\n",
    "\n",
    "## Infinite loop to get inputs until a blank entry\n",
    "def get_user_inputs():\n",
    "    quasi_identifiers = []\n",
    "    inputs = []\n",
    "    while True:\n",
    "        user_input = input(\"Enter a column name or index that is a quasi_identifier (leave blank to finish): \")\n",
    "        if user_input == \"\":\n",
    "            break\n",
    "        inputs.append(user_input)\n",
    "    for item in inputs:\n",
    "        try:\n",
    "            quasi_identifiers.append(int(item))\n",
    "        except ValueError:\n",
    "            quasi_identifiers.append(item)\n",
    "    return quasi_identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>name</td>\n",
       "      <td>type</td>\n",
       "      <td>state</td>\n",
       "      <td>oricodes</td>\n",
       "      <td>total_shootings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3145</td>\n",
       "      <td>Abbeville County Sheriff's Office</td>\n",
       "      <td>sheriff</td>\n",
       "      <td>SC</td>\n",
       "      <td>SC00100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2576</td>\n",
       "      <td>Aberdeen Police Department</td>\n",
       "      <td>local_police</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA01401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2114</td>\n",
       "      <td>Abilene Police Department</td>\n",
       "      <td>local_police</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX22101</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2088</td>\n",
       "      <td>Abington Township Police Department</td>\n",
       "      <td>local_police</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA04601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3187</td>\n",
       "      <td>Acadia Parish Sheriff's Office</td>\n",
       "      <td>sheriff</td>\n",
       "      <td>LA</td>\n",
       "      <td>LA00100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3375</td>\n",
       "      <td>Acworth Police Department</td>\n",
       "      <td>local_police</td>\n",
       "      <td>GA</td>\n",
       "      <td>GA03305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1241</td>\n",
       "      <td>Ada County Sheriff's Office</td>\n",
       "      <td>sheriff</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID00100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1615</td>\n",
       "      <td>Adair County Sheriff's Office</td>\n",
       "      <td>sheriff</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK00100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1978</td>\n",
       "      <td>Adams County Sheriff's Department</td>\n",
       "      <td>sheriff</td>\n",
       "      <td>CO</td>\n",
       "      <td>CO00100</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                    1             2      3         4  \\\n",
       "0    id                                 name          type  state  oricodes   \n",
       "1  3145    Abbeville County Sheriff's Office       sheriff     SC   SC00100   \n",
       "2  2576           Aberdeen Police Department  local_police     WA   WA01401   \n",
       "3  2114            Abilene Police Department  local_police     TX   TX22101   \n",
       "4  2088  Abington Township Police Department  local_police     PA   PA04601   \n",
       "5  3187       Acadia Parish Sheriff's Office       sheriff     LA   LA00100   \n",
       "6  3375            Acworth Police Department  local_police     GA   GA03305   \n",
       "7  1241          Ada County Sheriff's Office       sheriff     ID   ID00100   \n",
       "8  1615        Adair County Sheriff's Office       sheriff     OK   OK00100   \n",
       "9  1978    Adams County Sheriff's Department       sheriff     CO   CO00100   \n",
       "\n",
       "                 5  \n",
       "0  total_shootings  \n",
       "1                1  \n",
       "2                1  \n",
       "3                6  \n",
       "4                1  \n",
       "5                1  \n",
       "6                1  \n",
       "7                5  \n",
       "8                1  \n",
       "9               14  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass in the file path of the public data from user input\n",
    "file_path = input(\"Enter the file path for the data, as a CSV or Parquet file: \")\n",
    "if 'parquet' in file_path.lower():\n",
    "    df = pd.read_parquet(file_path)\n",
    "else:\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quasi_identifiers= [0, 2, 3, 4, 5]\n",
      "sensitive_attribute = 1\n"
     ]
    }
   ],
   "source": [
    "# Define the quasi-identifiers and sensitive attribute of data\n",
    "quasi_identifiers = get_user_inputs()\n",
    "print(\"quasi_identifiers=\", quasi_identifiers)\n",
    "user_input = input(\"Enter the column name or index that is the sensitive attribute: \") \n",
    "try:\n",
    "    sensitive_attribute = int(user_input)\n",
    "except:\n",
    "    sensitive_attribute = user_input \n",
    "print(\"sensitive_attribute =\", sensitive_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/6ytyl_l54r34xk4zb10_hq680000gn/T/ipykernel_87705/4221014718.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(quasi_identifiers).apply(diversity)\n",
      "/var/folders/gr/6ytyl_l54r34xk4zb10_hq680000gn/T/ipykernel_87705/4221014718.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(quasi_identifiers).apply(closeness)\n"
     ]
    }
   ],
   "source": [
    "df = flag_re_identifiability(df, quasi_identifiers, sensitive_attribute)\n",
    "\n",
    "# Flagging rows with >= 80% likelihood of re-identification\n",
    "df['re_identifiability_likelihood'] = np.where(\n",
    "    (df['k_anonymity'] <= (0.2 * len(df))) & \n",
    "    (df['l_diversity'] <= 1) & \n",
    "    (df['t_closeness'] >= (0.8 * df['t_closeness'].max())), \n",
    "    'High', 'Low'\n",
    ")\n",
    "high_risk_df = df[df['re_identifiability_likelihood'] == 'High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics summary\n",
    "stats_summary = {\n",
    "    'k_anonymity': df['k_anonymity'].describe(),\n",
    "    'l_diversity': df['l_diversity'].describe(),\n",
    "    't_closeness': df['t_closeness'].describe(),\n",
    "    'high_risk_rows_count': high_risk_df.shape[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the high risk dataframe and the overall statistics summary\n",
    "high_risk_df_copy = high_risk_df.copy()\n",
    "summary_df = pd.DataFrame(stats_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Indexes for High Risk Rows:\n",
      "3453  out of  3583  rows (96.37%)\n"
     ]
    }
   ],
   "source": [
    "# Listing the indexes of the rows in high_risk_df_copy\n",
    "high_risk_indexes = high_risk_df_copy.index.tolist()\n",
    "print(\"\\nNumber of Indexes for High Risk Rows:\")\n",
    "print(len(high_risk_indexes), \" out of \", len(df), \" rows ({}%)\".format(round((len(high_risk_indexes)/len(df))*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpretation of Summary Statistics:\n",
      "\n",
      "K-Anonymity: Mean: 1.0 (Moderate to High Risk)\n",
      "Median: 1.0 (Moderate to High Risk)\n",
      "\n",
      "L-Diversity: Mean: 1.0 (Moderate to High Risk)\n",
      "Median: 1.0 (Moderate to High Risk)\n",
      "\n",
      "T-Closeness: Mean: 0.999431139372551 (Moderate to High Risk)\n",
      "Median: 0.9997209042701647 (Moderate to High Risk)\n"
     ]
    }
   ],
   "source": [
    "# Displaying the dataframes - Interpretation\n",
    "print(\"\\nInterpretation of Summary Statistics:\")\n",
    "\n",
    "# Conditional interpretation for k-anonymity\n",
    "k_anonymity_mean = summary_df['k_anonymity']['mean']\n",
    "k_anonymity_median = summary_df['k_anonymity']['50%']\n",
    "if k_anonymity_mean > 20:\n",
    "    print(f\"\\nK-Anonymity: Mean: {k_anonymity_mean} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"\\nK-Anonymity: Mean: {k_anonymity_mean} (Moderate to High Risk)\")\n",
    "if k_anonymity_median > 20:\n",
    "    print(f\"Median: {k_anonymity_median} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"Median: {k_anonymity_median} (Moderate to High Risk)\")\n",
    "\n",
    "# Conditional interpretation for l-diversity\n",
    "l_diversity_mean = summary_df['l_diversity']['mean']\n",
    "l_diversity_median = summary_df['l_diversity']['50%']\n",
    "if l_diversity_mean > 5:\n",
    "    print(f\"\\nL-Diversity: Mean: {l_diversity_mean} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"\\nL-Diversity: Mean: {l_diversity_mean} (Moderate to High Risk)\")\n",
    "if l_diversity_median > 5:\n",
    "    print(f\"Median: {l_diversity_median} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"Median: {l_diversity_median} (Moderate to High Risk)\")\n",
    "\n",
    "# Conditional interpretation for t-closeness\n",
    "t_closeness_mean = summary_df['t_closeness']['mean']\n",
    "t_closeness_median = summary_df['t_closeness']['50%']\n",
    "if t_closeness_mean <= 0.05:\n",
    "    print(f\"\\nT-Closeness: Mean: {t_closeness_mean} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"\\nT-Closeness: Mean: {t_closeness_mean} (Moderate to High Risk)\")\n",
    "if t_closeness_median <= 0.05:\n",
    "    print(f\"Median: {t_closeness_median} (Low Risk)\")\n",
    "else:\n",
    "    print(f\"Median: {t_closeness_median} (Moderate to High Risk)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics Summary:\n",
      "\n",
      "Summary statistics for k_anonymity:\n",
      "Mean: 1.0\n",
      "Median: 1.0\n",
      "Standard Deviation: 0.0\n",
      "\n",
      "Summary statistics for l_diversity:\n",
      "Mean: 1.0\n",
      "Median: 1.0\n",
      "Standard Deviation: 0.0\n",
      "\n",
      "Summary statistics for t_closeness:\n",
      "Mean: 0.999431139372551\n",
      "Median: 0.9997209042701647\n",
      "Standard Deviation: 0.0012740892681340204\n",
      "\n",
      "Total Hish Risk Count: 3453 out of 3583, (96.37%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStatistics Summary:\")\n",
    "for column in summary_df.columns:\n",
    "    if column != 'high_risk_rows_count':\n",
    "        print(f\"\\nSummary statistics for {column}:\")\n",
    "        print(f\"Mean: {summary_df[column]['mean']}\")\n",
    "        print(f\"Median: {summary_df[column]['50%']}\")\n",
    "        print(f\"Standard Deviation: {summary_df[column]['std']}\")\n",
    "print(f\"\\nTotal Hish Risk Count: {summary_df['high_risk_rows_count']['count']} out of {len(df)}, ({round((summary_df['high_risk_rows_count']['count']/len(df))*100, 2)}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
